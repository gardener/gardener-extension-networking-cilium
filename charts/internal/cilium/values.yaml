requirements:
  # Include the cilium-agent DaemonSet
  agent:
    enabled: true

  # Include the cilium-operator Deployment
  operator:
    enabled: true

  # Include the Hubble deployment
  hubble:
    enabled: false

# global groups all configuration options that have effect on all sub-charts
global:
  configMapHash: ""
  configMapLabelPrefixHash: ""

  egressGateway:
    enabled: false

  nodeLocalDNS:
    enabled: false

  podCIDR: ""
  nodeCIDR: ""

  ipv4NativeRoutingCIDR: ""

  snatToUpstreamDNS:
    enabled: false

  snatOutOfCluster:
    enabled: false

  mtu:

  # pullPolicy is the container image pull policy
  pullPolicy: IfNotPresent

  # -- Configure iptables--random-fully. Disabled by default. View https://github.com/cilium/cilium/issues/13037 for more information.
  iptablesRandomFully: true

  hubble:
    socketPath: "/var/run/cilium/hubble.sock"
    clusterName: default
    peerService: "hubble-peer.kube-system.svc.cluster.local.:443"
    peerPort: 4244
    enabled: true
    listenAddress: ":4244"
    metrics:
      enabled:
      - dns
      - drop
      - tcp
      - flow
      - port-distribution
      - icmp
      - httpV2:labelsContext=source_ip,source_namespace,source_workload,destination_ip,destination_namespace,destination_workload,traffic_direction
      port: 9091
    tls:
      enabled: true
      auto:
        enabled: true
      certFile: /var/lib/cilium/tls/hubble/server.crt
      keyFile: /var/lib/cilium/tls/hubble/server.key
      clientCAFiles: /var/lib/cilium/tls/hubble/client-ca.crt

  # identityAllocationMode is the method to use for identity allocation.
  # Supported modes:
  #  crd: Kubernetes CRD backing
  #  kvstore: Key-value store backend (better scalability)
  identityAllocationMode: crd

  endpointGCInterval: "5m0s"

  nodesGCInterval: "5m0s"

  # Disable the usage of CiliumEndpoint CRD
  disableEndpointCrd: false

  # ipv4 is the IPv4 addressing configuration
  ipv4:
    enabled: true

  # ipv6 is the IPv6 addressing configuration
  ipv6:
    enabled: false

  # debug enables debugging mode
  debug:
    enabled: false

    # verbose allows additional levels of debug/trace messaging
    #verbose: flow
  agent:
    # TCP port for the agent health API. This is not the port for cilium-health.
    healthPort: 9879
    # Do not run Cilium agent when running with clean mode. Useful to completely
    # uninstall Cilium as it will stop Cilium from starting and create artifacts
    # in the node.
    sleepAfterInit: false
    # Keep the deprecated probes when deploying Cilium DaemonSet
    keepDeprecatedProbes: false
    # The agent can be put into the following three policy enforcement modes
    # default, always and never.
    # https://docs.cilium.io/en/latest/policy/intro/#policy-enforcement-modes
    policyMode: default

  # prometheus enables
  prometheus:
    enabled: true
    port: 9090
    serviceMonitor:
      enabled: false

  operatorHighAvailability:
    enabled: true

  # operatorPrometheus enables
  operatorPrometheus:
    enabled: true
    port: 6942

  # enableXTSocketFallback enables the fallback compatibility solution
  # when the xt_socket kernel module is missing and it is needed for
  # the datapath L7 redirection to work properly.  See documentation
  # for details on when this can be disabled:
  # http://docs.cilium.io/en/latest/install/system_requirements/#admin-kernel-version.
  enableXTSocketFallback: true

  # installIptablesRules enables installation of iptables rules to allow for
  # TPROXY (L7 proxy injection), itpables based masquerading and compatibility
  # with kube-proxy. See documentation for details on when this can be
  # disabled.
  installIptablesRules: true

  # This option, by default set to false,
  # installs some extra Iptables rules to skip netfilter connection tracking on all pod traffic.
  # Disabling connection tracking is only possible when Cilium is running
  # in direct routing mode and is using the kube-proxy replacement.
  # Moreover, this option cannot be enabled when Cilium is running in a managed Kubernetes environment
  # or in a chained CNI setup.
  installNoConntrackIptablesRules: false

  # masquerade enables masquerading of traffic leaving the node for
  # destinations outside of the cluster.
  enableIpv4Masquerade: true
  enableIpv6Masquerade: false
  enableBPFMasquerade: true

  enableIpv4BigTCP : false
  enableIpv6BigTCP: false

  # ipMasqAgent enables and controls BPF ip-masq-agent
  ipMasqAgent:
    enabled: false

  # autoDirectNodeRoutes enables installation of PodCIDR routes between worker
  # nodes if worker nodes share a common L2 network segment.
  autoDirectNodeRoutes: false

  localRedirectPolicy:
    enabled: false

  # endpointRoutes enables use of per endpoint routes instead of routing vis
  # the cilium_host interface
  endpointRoutes:
    enabled: false

  # cni is the CNI configuration
  cni:
    # install determines whether to install the CNI configuration and binary
    # files into the filesystem.
    install: true

    # -- Remove the CNI configuration and binary files on agent shutdown. Enable this
    # if you're removing Cilium from the cluster. Disable this to prevent the CNI
    # configuration file from being removed during agent upgrade, which can cause
    # nodes to go unmanageable.
    uninstall: false

    # chainingMode enables chaining on top of other CNI plugins. Possible
    # values:
    #  - none
    #  - generic-veth
    #  - aws-cni
    #  - portmap
    chainingMode: none

    # customConf skips writing of the CNI configuration. This can be used if
    # writing of the CNI configuration is performed by external automation.
    customConf: false

    # confPath is the path to the CNI configuration directory on the host
    confPath: /etc/cni/net.d

    # binPath si the path to the CNI binary directory on the host
    binPath: /opt/cni/bin

    # configMap when defined, will mount the provided value as ConfigMap  and
    # interpret the cniConf variable as CNI configuration file and write it
    # when the agent starts up
    # configMap: cni-configuration

    # configMapKey is the key in the CNI ConfigMap to read the contents of the
    # CNI configuration from
    configMapKey: cni-config

    # confFileMountPath is the path to where to mount the ConfigMap inside the
    # pod
    confFileMountPath: /tmp/cni-configuration

    # hostConfDirMountPath is the path to where the CNI configuration directory
    # is mounted inside the  pod
    hostConfDirMountPath: /host/etc/cni/net.d

    # -- Make Cilium take ownership over the `/etc/cni/net.d` directory on the
    # node, renaming all non-Cilium CNI configurations to `*.cilium_bak`.
    # This ensures no Pods can be scheduled using other CNI plugins during Cilium
    # agent downtime.
    exclusive: true
    
    # -- Configure the log file for CNI logging with retention policy of 7 days.
    # Disable CNI file logging by setting this field to empty explicitly.
    logFile: "/var/run/cilium/cilium-cni.log"

  # cluster is the clustermesh related configuration
  cluster:
    # name is the human readable name of the cluster when setting up
    # clustermesh
    name: default
    # Unique ID of the cluster. Must be unique across all conneted clusters and
    # in the range of 1 and 255. Only relevant when building a mesh of clusters.
    #id: "1"

  # tunnel is the encapsulation configuration for communication between nodes
  # Possible values:
  #   - disabled
  #   - vxlan (default)
  #   - geneve
  tunnel: "vxlan"

  # containerRuntime enables container runtime specific integration. Supported
  # values:
  # - containerd
  # - crio
  # - docker
  # - none
  # - auto (automatically detect the container runtime)
  containerRuntime:
    integration: none

    # socketPath can be used to configure the path to the container runtime
    # control socket, if it is on a non-standard path.
    #socketPath:

  # Enables the BGP control plane
  bgpControlPlane:
    enabled: false

  # bpf is the BPF datapath specific configuration
  bpf:
    # preallocateMaps enables pre allocation of BPF map values. This increases
    # memory usage but can reduce latency.
    preallocateMaps: false

    # ctTcpMax is the maximum number of entries in the TCP connection tracking
    # table
    ctTcpMax: 524288

    # ctAnyMax is the maximum number of entries for the non-TCP connection
    # tracking table
    ctAnyMax: 262144

    # natMax is the maximum number of entries for the NAT table
    natMax: 524288

    # montiorAggregation is the level of aggregation for datapath trace events
    monitorAggregation: medium

    # monitorInterval is the typical time between monitor notifications for
    # active connections
    monitorInterval: "5s"

    # monitorFlags are TCP flags that trigger notifications when seen for the
    # first time
    monitorFlags: "all"

    # bpf-policy-map-max specifies the maximum number of entries in endpoint
    # policy map (per endpoint)
    policyMapMax: "65536"

    # bpf-lb-map-max specifies the maximum number of entries in bpf lb service,
    # backend and affinity maps.
    lbMapMax: "65536"

    # Specifies the bpf load balancing mode ("snat", "dsr", "hybrid")
    lbMode: "snat"

    # bpf-lb-bypass-fib-lookup instructs Cilium to enable the FIB lookup bypass
    # optimization for nodeport reverse NAT handling.
    lbExternalClusterip: "false"

    # -- (bool) Enable loadBalancerSourceRanges CIDR filtering for all service
    # types, not just LoadBalancer services. The corresponding NodePort and
    # ClusterIP (if enabled for cluster-external traffic) will also apply the
    # CIDR filter.
    # @default -- `false`
    lbSourceRangeAllTypes: false

    # -- (bool) Enable the option to define the load balancing algorithm on
    # a per-service basis through service.cilium.io/lb-algorithm annotation.
    # @default -- `false`
    lbAlgorithmAnnotation: false

    # -- (bool) Enable the option to define the load balancing mode (SNAT or DSR)
    # on a per-service basis through service.cilium.io/forwarding-mode annotation.
    # @default -- `false`
    lbModeAnnotation: false

  # Enable socket-based LB for E/W traffic
  bpfSocketLB:
    enabled: false

  # bpf-lb-sock-hostns-only skip socket LB for services when inside a pod namespace, in favor of service LB at the pod interface.
  # Socket LB is still used when in the host namespace. Required by service mesh (e.g., Istio, Linkerd).
  bpfSocketLBHostnsOnly:
    enabled: false

  # encryption is the encryption specific configuration
  encryption:
    # enabled enables encryption
    enabled: false

    # keyFile is the name of the key file inside the Kubernetes secret
    # configured via secretName
    keyFile: keys

    # mountPath is the path where to mount the secret inside the Cilium pod
    mountPath: /etc/ipsec

    # secretName is the name of the Kubernetes secret containing the encryption
    # keys
    secretName: cilium-ipsec-keys

    # nodeEncryption enables encryption for pure node to node traffic
    nodeEncryption: false

    # interface is the interface to use for encryption
    # interface: eth0

  # kubeProxyReplacement enables kube-proxy replacement in Cilium BPF datapath
  kubeProxyReplacement: "false"

  kubeProxyReplacementHealthzBindAddr: ""

  # Enable check of service source ranges (currently, only for LoadBalancer)
  enableSvcSrcRangeCheck: true

  # hostServices is the configuration for ClusterIP service handling in host namespace
  hostServices:
    # enabled enables host reachable functionality
    enabled: false

    # protocols is the list of protocols to support
    protocols: tcp,udp

  # Configure service load balancing
  loadBalancer:
    # serviceTopology enables K8s Topology Aware Hints -based service
    # endpoints filtering
    serviceTopology: true

  # hostPort is the configuration for HostPort service handling
  hostPort:
    # enabled enables HostPort functionality
    enabled: false

  # nodePort is the configuration for NodePort service handling
  nodePort:
    # enabled enables NodePort functionality
    enabled: false

    # range is the port range to use for NodePort
    # range:

    # device is the name of the device handling NodePort requests
    # device:

    # mode is the mode of NodePort feature
    mode: "hybrid"

    #  Append NodePort range to net.ipv4.ip_local_reserved_ports if it overlaps with ephemeral port range (net.ipv4.ip_local_port_range)
    autoProtectPortRange: true

    # Reject application bind(2) requests to service ports in the NodePort range
    bindProtection: true

  # externalIPs is the configuration for ExternalIPs service handling
  externalIPs:
    # enabled enables ExternalIPs functionality
    enabled: false

  # pprof is the GO pprof configuration
  pprof:
    # enabled enables go pprof debugging
    enabled: false

  # logSytemLoad enables logging of system load
  logSystemLoad: false

  # sockops is the BPF socket operations configuration
  sockops:
    # enabled enables installation of socket level functionality.
    enabled: false

  # ENI mode configures the options required to run with ENI
  eni: false

  azure:
    enabled: false
    #resourceGroup: group1
    #subscriptionID: 00000000-0000-0000-0000-000000000000
    #tenantID: 00000000-0000-0000-0000-000000000000
    #clientID: 00000000-0000-0000-0000-000000000000
    #clientSecret: 00000000-0000-0000-0000-000000000000

  # cleanState instructs the cilium-agent DaemonSet to clean all state in the
  # initContainer
  #
  # WARNING: Use with care!
  cleanState: false

  # cleanBpfState instructs the cilium-agent DaemonSet to clean all BPF
  # datapath state in the initContainer
  #
  # WARNING: Use with care!
  cleanBpfState: false

  daemon:
    runPath: "/var/run/cilium"

  wellKnownIdentities:
    # enabled enables the use of well-known identities
    enabled: false

  tls:
    secretsBackend: local

  apiRateLimit: false

  synchronizeK8sNodes: true

  # Enables L7 proxy for L7 policy enforcement and visibility
  l7Proxy:
    enabled: true

  ipam:
    mode: "kubernetes"
    operator:
      clusterPoolIPv4PodCIDR: "10.0.0.0/8"
      clusterPoolIPv4MaskSize: 24
      clusterPoolIPv6PodCIDR: "fd00::/104"
      clusterPoolIPv6MaskSize: 120

  l2NeighDiscovery:
    enabled: true

  # Period for remote node ARP entry refresh
  arpingRefreshPeriod: "30s"

  enableK8SNetworkpolicy: true

  # -- Enable endpoint lockdown on policy map overflow.
  endpointLockdownOnMapOverflow: false

  endpointHealthChecking:
    enabled: true
  # -- Number of ICMP requests sent for each health check before marking a node or endpoint unreachable.
  healthCheckICMPFailureThreshold: 3

  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            k8s-app: cilium
        topologyKey: kubernetes.io/hostname

  # enables non-drop mode for installed policies. In audit mode
  # packets affected by policies will not be dropped. Policy related
  # decisions can be checked via the poicy verdict messages.
  policyAuditMode: false
  securityContext:
    capabilities:
      # -- Capabilities for the `cilium-agent` container
      ciliumAgent:
        # Use to set socket permission
        - CHOWN
        # Used to terminate envoy child process
        - KILL
        # Used since cilium modifies routing tables, etc...
        - NET_ADMIN
        # Used since cilium creates raw sockets, etc...
        - NET_RAW
        # Used since cilium monitor uses mmap
        - IPC_LOCK
        # Used in iptables. Consider removing once we are iptables-free
        - SYS_MODULE
        # We need it for now but might not need it for >= 5.11 specially
        # for the 'SYS_RESOURCE'.
        # In >= 5.8 there's already BPF and PERMON capabilities
        - SYS_ADMIN
        # Could be an alternative for the SYS_ADMIN for the RLIMIT_NPROC
        - SYS_RESOURCE
        # Both PERFMON and BPF requires kernel 5.8, container runtime
        # cri-o >= v1.22.0 or containerd >= v1.5.0.
        # If available, SYS_ADMIN can be removed.
        #- PERFMON
        #- BPF
        # Allow discretionary access control (e.g. required for package installation)
        - DAC_OVERRIDE
        # Allow to set Access Control Lists (ACLs) on arbitrary files (e.g. required for package installation)
        - FOWNER
        # Allow to execute program that changes GID (e.g. required for package installation)
        - SETGID
        # Allow to execute program that changes UID (e.g. required for package installation)
        - SETUID

  images:
    cilium-agent: "image-repository:image-tag"
    cilium-operator: "image-repository:image-tag"

    hubble: "image-repository:image-tag"
    hubble-relay: "image-repository:image-tag"
    hubble-ui: "image-repository:image-tag"
    hubble-ui-backend: "image-repository:image-tag"
    certgen: "image-repository:image-tag"

    kube-proxy: "image-repository:image-tag"
